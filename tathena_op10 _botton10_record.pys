import datetime

# ------------------------------
# Athena Row Count SQL Generator
# ------------------------------
# This script generates an Athena SQL query that returns row counts
# for a list of tables in a given schema.
#
# HOW TO USE:
# - Set your schema name in `schema_name`
# - Provide the list of tables in `table_list`
# - Run the script to output a .sql file with the query
# ------------------------------

# === CONFIGURATION ===
schema_name = 'your_schema_name_here'  # Example: 'my_athena_database'

# List of table names in the schema you want to query
table_list = [
    'table1',
    'table2',
    'table3',
    # Add more tables as needed
]

# === QUERY GENERATION ===
today = datetime.date.today().strftime("%Y-%m-%d")
query_lines = ["-- Athena query to get row counts per table\n"]
query_lines.append("WITH table_counts AS (")

for i, table in enumerate(table_list):
    table = table.strip()
    union_prefix = "UNION ALL" if i > 0 else ""
    query_lines.append(f"""{union_prefix}
    SELECT 
        '{schema_name}' AS schema_name,
        '{table}' AS table_name,
        COUNT(*) AS total_count,
        DATE('{today}') AS as_of_today
    FROM {schema_name}.{table}""")

query_lines.append(")\nSELECT * FROM table_counts;")

# === OUTPUT FILE ===
output_filename = f"{schema_name}_table_counts_{today}.sql"
with open(output_filename, "w") as f:
    f.write("\n".join(query_lines))

print(f" Athena query saved to '{output_filename}'")

## Script 2 top10 and bottom 10, update values where <>

import os

# Parameters
schema_name = '<athena_schema_name>'


table_list = [tab1', 'tab2']
# to get the column info 
# SELECT 
#     table_schema,
#     table_name,
#     array_join(array_agg(column_name ORDER BY ordinal_position), ', ') AS column_list
# FROM information_schema.columns
# WHERE table_schema = '<athena_schema_name>''  -- Replace with your schema name
# GROUP BY table_schema, table_name
# ORDER BY table_name;

# updated 

# SELECT 
#     table_schema,
#     table_name,
#     '''' || table_name || '''' || ': [' || 
#     array_join(
#         array_agg(
#             '''' || column_name || ''''  
#             ORDER BY ordinal_position
#         ), 
#         ', '
#     ) || '],' AS formatted_table_columns
# FROM information_schema.columns
# WHERE table_schema = '<athena_schema_name>''
# GROUP BY table_schema, table_name
# ORDER BY table_name;

# Define actual columns for each table
table_columns_map = {
'tabl': ['col1', 'col2'],
'tab2': ['col3'],

}

# Output directory for generated SQLs
output_dir = '<define_output_dir>'
os.makedirs(output_dir, exist_ok=True)


def generate_sql(schema_name, table_name, columns):
    cte_list = []         # Initialize CTE list
    final_selects = []    # Initialize SELECT statements list

    for col in columns:
        col_safe = col.replace('"', '')

        # CTEs for type, stats, top10, bottom10, and final result
        cte_list.extend([
            f"""{col_safe}_type AS (
    SELECT '{col_safe}' AS column_name,
           typeof({col_safe}) AS data_type
    FROM {schema_name}.{table_name}
    WHERE {col_safe} IS NOT NULL
    LIMIT 1
)""",
            f"""{col_safe}_stats AS (
    SELECT
        COUNT(*) AS total_count,
        COUNT(DISTINCT {col_safe}) AS distinct_count
    FROM {schema_name}.{table_name}
)""",
            f"""{col_safe}_top10 AS (
    SELECT LISTAGG(CAST(val AS VARCHAR), ', ') 
           WITHIN GROUP (ORDER BY cnt DESC, val) AS top_10_values
    FROM (
        SELECT {col_safe} AS val, COUNT(*) AS cnt
        FROM {schema_name}.{table_name}
        WHERE {col_safe} IS NOT NULL
        GROUP BY {col_safe}
        ORDER BY cnt DESC, val
        LIMIT 10
    )
)""",
            f"""{col_safe}_bottom10 AS (
    SELECT LISTAGG(CAST(val AS VARCHAR), ', ') 
           WITHIN GROUP (ORDER BY cnt ASC, val) AS bottom_10_values
    FROM (
        SELECT {col_safe} AS val, COUNT(*) AS cnt
        FROM {schema_name}.{table_name}
        WHERE {col_safe} IS NOT NULL
        GROUP BY {col_safe}
        ORDER BY cnt ASC, val
        LIMIT 10
    )
)""",
            f"""{col_safe}_result AS (
    SELECT
        '{schema_name}' AS schema_name,
        '{table_name}' AS table_name,
        t.column_name,
        t.data_type,
        s.total_count,
        s.distinct_count,
        top.top_10_values,
        bot.bottom_10_values
    FROM {col_safe}_type t
    CROSS JOIN {col_safe}_stats s
    CROSS JOIN {col_safe}_top10 top
    CROSS JOIN {col_safe}_bottom10 bot
)"""
        ])

        # Final SELECT for each column result
        final_selects.append(f"SELECT * FROM {col_safe}_result")
   # Join all CTEs and final SELECTs
    ctes_sql = ",\n\n".join(cte_list)
    final_sql = "-- Athena profiling query for table: {}.{}\nWITH\n{}\n\n-- Final union\n{};".format(
        schema_name,
        table_name,
        ctes_sql,
        "\nUNION ALL\n".join(final_selects)
    )
    return final_sql.strip()


# Generate SQLs per table and write to file
for table in table_list:
    if table not in table_columns_map:
        print(f" Skipping '{table}': No columns defined.")
        continue

    columns = table_columns_map[table]
    sql_text = generate_sql(schema_name, table, columns)
    file_path = os.path.join(output_dir, f"{table}.sql")

    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(sql_text)

    print(f" SQL generated for table: {table} â†’ {file_path}")

# bulk execution but don't know the OUTPUT_LOCATION
# #!/bin/bash

# DATABASE="your_database_name"   # <-- Replace this with your Athena database name
# OUTPUT_LOCATION="s3://your-athena-results-bucket/folder/"  # <-- Replace with your Athena query results S3 bucket

# SQL_DIR="/home/cloudshell-user/"

# for sqlfile in "$SQL_DIR"/*.sql
# do
#   echo "Running $sqlfile..."

#   QUERY_STRING=$(<"$sqlfile")

#   QUERY_EXECUTION_ID=$(aws athena start-query-execution \
#     --query-string "$QUERY_STRING" \
#     --query-execution-context Database=$DATABASE \
#     --result-configuration OutputLocation=$OUTPUT_LOCATION \
#     --output text --query 'QueryExecutionId')

#   echo "QueryExecutionId: $QUERY_EXECUTION_ID"

#   # Poll for query completion
#   STATUS="RUNNING"
#   while [[ "$STATUS" == "RUNNING" || "$STATUS" == "QUEUED" ]]; do
#     sleep 5
#     STATUS=$(aws athena get-query-execution --query-execution-id $QUERY_EXECUTION_ID --query 'QueryExecution.Status.State' --output text)
#     echo "Status: $STATUS"
#   done

#   if [[ "$STATUS" == "SUCCEEDED" ]]; then
#     echo "Query $sqlfile succeeded."
#   else
#     echo "Query $sqlfile failed with status $STATUS."
#   fi

# done
